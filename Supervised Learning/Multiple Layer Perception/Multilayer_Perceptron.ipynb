{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multilayer Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multilayer Perceptron\n",
        "## Definition \n",
        "A feedforward artificial neural network that creates a set of outputs from a set of inputs is known as a multilayer perceptron (MLP). An MLP is defined by numerous layers of input nodes that are linked as a directed graph between the input and output layers. Backpropogation is used by MLP to train the network.\n",
        "\n",
        "![](https://static.packt-cdn.com/products/9781786468574/graphics/B05474_04_05.jpg)\n",
        "\n",
        "There are at least three levels of nodes in an MLP: an **input layer**, a **hidden layer**, and an **output layer**. Each node, with the exception of the input nodes, is a neuron with a nonlinear activation function. Backpropagation is a supervised learning technique used by MLP during training. MLP is distinguished from a linear perceptron by its numerous layers and non-linear activation. It can tell the difference between data that isn't linearly separable."
      ],
      "metadata": {
        "id": "SCkg8vd63S7i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0UGxRRnjx0z"
      },
      "source": [
        "## Notion Summary\n",
        "* $a_i^{\\ell}$: output of a neuron\n",
        "* $\\omega_{ij}^{\\ell}$: the weight from mode j to mode i in the $\\ell_{th}$ layer\n",
        "* $z_i^{\\ell}$: input of activation function\n",
        "* $b_i^{\\ell}$: the i-th bias in the layer $\\ell$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvpUA0VEXgGI"
      },
      "source": [
        "## Layer Output Relation\n",
        "* from a to z\n",
        "$$z_i^{\\ell} = \\omega_{i1}^1a_1^{\\ell-1}+\\omega_{i2}^1a_2^{\\ell-1}+...+b_i^{\\ell}$$\n",
        "\n",
        "* from z to a\n",
        "$$a_i^{\\ell} = \\sigma(z_i^{\\ell})$$\n",
        "\n",
        "* General Version\n",
        "  * $a^0$ = x\n",
        "  * for $\\ell$ = 1 to L\n",
        "$$\\begin{aligned}\n",
        "z^{\\ell} &= W^{\\ell}a^{\\ell-1}+b^{\\ell}\\\\\n",
        "a^{\\ell}&=\\sigma(z^{\\ell})\\\\\n",
        "a^{\\ell}&=\\sigma(W^{\\ell}a^{\\ell-1}+b^{\\ell})\n",
        "\\end{aligned}\n",
        "$$\n",
        "  * Finish with $a^{\\ell}$, our output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLhiQHbgXxuT"
      },
      "source": [
        "## Neural Network Formulation\n",
        "\\begin{aligned}\n",
        "a^1&=\\sigma(W^1x+b^1)\\\\\n",
        "a^2&=\\sigma(W^2a^1+b^2)\\\\\n",
        "& \\cdots\\\\\n",
        "a^L&=\\sigma(W^La^{L-1}+b^L)\\\\\n",
        "y&=\\sigma(W^L \\cdots\\sigma(W^2\\sigma(W^1x+b^1)+b^2)\\cdots+b^L)\n",
        "\\end{aligned}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Linear Activation Function\n",
        "* Without non-linearity, deep neural networks work the same as linear transform\n",
        "$$W_1(W_2\\cdot x)=(W_1W_2) x=Wx$$\n",
        "* With non-linearity, networks with more layers can estimate more complicated function\n",
        "  * **Sigmoid**: $\\text{sigmoid(x)}=\\frac{1}{1+e^{-x}}$\n",
        "\n",
        "  * **tanh**: $\\text{tanh(x)}=\\frac{sinh(x)}{cosh(x)}=\\frac{e^x-e^{-x}}{e^x+e^{-x}}$\n",
        "\n",
        "  * **Rectified Linear Unit**: ReLU(x) = max(x, 0)\n",
        "\n",
        "![](https://www.researchgate.net/profile/Hoon-Chung-2/publication/309775740/figure/fig1/AS:538049215381504@1505292337270/The-most-common-nonlinear-activation-functions.png)"
      ],
      "metadata": {
        "id": "pEBub6x66M_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##  Cost function\n",
        "$$C(w,b;x,y)=\\frac{1}{2}\\sum_{i=1}^n(\\alpha_i^L-y_i)^2$$\n",
        "\n",
        "\n",
        "## Output Error\n",
        "$$\\delta^{\\ell-1} = \\nabla_{a^{\\ell-1}}\\ C \\otimes \\sigma' (z^{\\ell-1})$$\n",
        "\n",
        "\n",
        "\n",
        "## Neuron Error\n",
        "For $\\ell = L-2,\\cdots,1$, based on output error, the neuron error is: $$\\delta^{\\ell}=\\bigg(\\big(w^{\\ell+1}\\big) ^T\\delta^{\\ell+1}\\bigg) \\otimes\\sigma'(z^{\\ell})$$\n",
        "\n",
        "\n",
        "## The Gradient Approximation Update Rule\n",
        "  \\begin{aligned}\n",
        "\\frac{\\partial C}{\\partial w^{\\ell}}&=\\delta^{\\ell}(a^{\\ell-1})^T\\\\\n",
        "\\frac{\\partial C}{\\partial b^{\\ell}}&=\\delta^{\\ell}\\\\\n",
        "w^{\\ell} &= w^{\\ell}-\\alpha\\frac{\\partial C}{\\partial w^{\\ell}}\\\\\n",
        "b^{\\ell} &= b^{\\ell}-\\alpha\\frac{\\partial C}{\\partial b^{\\ell}}\n",
        "\\end{aligned}\n"
      ],
      "metadata": {
        "id": "4MqhZH5m6KmK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4xpKIneqWe0"
      },
      "source": [
        "## Batch Gradient Descent vs. SGD vs. Mini-Batch SGD\n",
        "  * **Batch Gradient Descent**: To perform a single step in Batch Gradient Descent, all of the training data is considered. We take the **mean** gradient of all the gradients in the training instances and use it to update our parameters. So that's only one gradient descent step in one era.\n",
        "  $$\\theta^{i+1} = \\theta^i - \\eta \\frac{1}{K}\\sum_k\\nabla C_k(\\theta^i)$$\n",
        "\n",
        "  * **Stochastic Gradient descent(SGD)**: In Stochastic Gradient Descent (SGD), we consider just **one example** at a time to take a single step. \n",
        "  $$\\theta^{i+1} = \\theta^i - \\eta \\nabla C_k(\\theta^i)$$\n",
        "  * **Mini-Batch SGD**: A mini-batch is a **batch** of a defined number of training samples that is smaller than the full dataset.\n",
        "  $$\\theta^{i+1} = \\theta^i - \\eta \\frac{1}{B}\\sum_{x_k \\in b}\\nabla C_k(\\theta^i)$$\n",
        "\n",
        "  * Training speed: mini-batch > SGD > Gradient Descent\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqxDpjRWyL42"
      },
      "source": [
        "## Backpropagation Networks\n",
        "A Backpropagation (BP) Network is a feed-forward multilayer perceptron network with differentiable activation functions in each layer. Backpropagation Learning is done in 3 stages:\n",
        "\n",
        "* The input training pattern is feed-forward.\n",
        "* The error between actual output and target values are calculated.\n",
        "* The weights update.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn95hxE_1-8l"
      },
      "source": [
        "## Steps\n",
        "* Initialize the weights and bias with small-randomized values.\n",
        "* Propagate all values in the input layer until output layer(Forward Propagation).\n",
        "* Update weight and bias in the inner layers(Backpropagation).\n",
        "* Do it until that the stop criterion is satisfied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmYmEpgb2iIa"
      },
      "source": [
        "## Data\n",
        "[CIFAR10 small images classification dataset](https://keras.io/api/datasets/cifar10/)\n",
        "\n",
        "This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 10 categories. \n",
        "The classes are:\n",
        "* 0 airplane\n",
        "* 1\tautomobile\n",
        "* 2\tbird\n",
        "* 3\tcat\n",
        "* 4\tdeer\n",
        "* 5\tdog\n",
        "* 6\tfrog\n",
        "* 7\thorse\n",
        "* 8\tship\n",
        "* 9\ttruck\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package \n",
        "* [tensorflow](https://www.tensorflow.org)\n",
        "* [numpy](https://numpy.org)\n",
        "* [matplotlib.pyplot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html)"
      ],
      "metadata": {
        "id": "FPuyYAJ99lo8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ORhPxVx_KWp"
      },
      "source": [
        "from tensorflow import keras # to load the data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "FcMMMGALO8KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "Zq4XYmtlAVmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c26522b-9e96-44f4-cef4-146894ebe605"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the first image of training data"
      ],
      "metadata": {
        "id": "fasHx-DjBbsZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Z3MO8_jX_mVI",
        "outputId": "40620563-4374-4532-cccc-38e15c1d0faa"
      },
      "source": [
        "plt.imshow(x_train[0])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fab5e74cd50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The range of x_train for each picture is from 0 to 225."
      ],
      "metadata": {
        "id": "s3tZhWCcBnUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.min(x_train),np.max(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNbodxcOBSbS",
        "outputId": "2ac0d5dc-54fa-47aa-99e2-83b16d6327f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 255)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's scale x_train and x_test"
      ],
      "metadata": {
        "id": "G-enl4HbB9aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "metadata": {
        "id": "nwzaho1jB6vL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To feed into the network, et's flat X to change the matrix shape to a vector. \n",
        "\n",
        "Check the flatten function and the shape."
      ],
      "metadata": {
        "id": "pns-g4eaCc-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].flatten().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pDZ74CmCcSZ",
        "outputId": "eaf1ec82-a3a6-4259-a255-9fcd54a4ae40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3072,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's reshape it to a vector with 3072 rows and 1 column."
      ],
      "metadata": {
        "id": "LeKLJpK1DTfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].flatten().reshape(3072, 1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm-eruG-Dsi5",
        "outputId": "de89536b-43da-4490-8b0c-004f818845b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3072, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create for loops to flatten the X matrix. The label vectors are temporarily stored in Y."
      ],
      "metadata": {
        "id": "YHcIsWCqE1Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X will temp store flattened matrices\n",
        "X = []\n",
        "for x in x_train:\n",
        "  X.append(x.flatten().reshape(3072, 1))\n",
        "\n",
        "# Y will temp store one-hot encoded label vectors\n",
        "Y = []\n",
        "for y in y_train:\n",
        "  temp_vec = np.zeros((10, 1))\n",
        "  temp_vec[y][0] = 1.0\n",
        "  Y.append(temp_vec)\n",
        "\n",
        "# Our data will be stored as a list of tuples. \n",
        "train_data = [p for p in zip(X, Y)]"
      ],
      "metadata": {
        "id": "ymJeC3L2EP7_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = train_data[0]\n",
        "print(p[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T2Owo3bX6fb",
        "outputId": "3e780f2c-03ff-4a1a-ccf3-f9e3ebbfd7d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the shape of p and the shape of training data."
      ],
      "metadata": {
        "id": "3P21_MAaYkar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrrFUvOqYsub",
        "outputId": "47b0d3f9-f19f-4219-9fc1-c3ab2b055db9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3072, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(train_data).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K--6r8LYzBg",
        "outputId": "15c066d7-4775-405f-dc02-6377fbae4e36"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do the same work to test data."
      ],
      "metadata": {
        "id": "1T7sVqG7Y1o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "for x in x_test:\n",
        "  X.append(x.flatten().reshape(3072, 1))\n",
        "\n",
        "Y = []\n",
        "for y in y_test:\n",
        "  temp_vec = np.zeros((10, 1))\n",
        "  temp_vec[y][0] = 1.0\n",
        "  Y.append(temp_vec)\n",
        "\n",
        "test_data = [p for p in zip(X, Y)]"
      ],
      "metadata": {
        "id": "SbAABXXBY7e2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm Steup"
      ],
      "metadata": {
        "id": "i4ynFChiP603"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation Function \n",
        "Define activation function and their first derivative\n",
        "\n",
        "The first derivative of the sigmoid function is:\n",
        "$$\\sigma'(z)=\\sigma(z)(1-\\sigma(z))$$"
      ],
      "metadata": {
        "id": "YqdCzqymZOg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "  return sigmoid(z)*(1.0-sigmoid(z))\n"
      ],
      "metadata": {
        "id": "wgGRPcbkZN1A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first derivative of the tanh function is:\n",
        "$$\\text{tanh}'(z) = 1- (\\text{tanh}(z))^2$$"
      ],
      "metadata": {
        "id": "nq3IyyPjdfJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh(z):\n",
        "  return np.tanh(z)\n",
        "\n",
        "def tanh_prime(z):\n",
        "  return 1.0 - (np.tanh(z))**2\n"
      ],
      "metadata": {
        "id": "n1Lh9OBbcCSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first derivative of the relu function is:\n",
        "$$\\text{relu}'(z) = \\text{where}(z > 0, 1.0, 0)$$"
      ],
      "metadata": {
        "id": "MchH0GvWeEsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(z):\n",
        "  np.maximum(0, z)\n",
        "\n",
        "def relu_prime(z):\n",
        "  return np.where(z > 0, 1.0, 0)"
      ],
      "metadata": {
        "id": "IvyzciMkd7To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function\n",
        "The cost function is:\n",
        "$$C(w,b;x,y)=\\frac{1}{2}\\sum_{i=1}^n(\\alpha_i^L-y_i)^2$$"
      ],
      "metadata": {
        "id": "ieUwQTw-cjbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(a, y):\n",
        "  return .5*sum((a[i]-y[i])**2 for i in range(10))[0]"
      ],
      "metadata": {
        "id": "nP8plZF7cjGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial weights and bias.  \n",
        "The number of nodes in the four layers is 3072, 60, 60, 10, respectively. Thus, the dimentions of weights are (60, 3027), (60,60), (10,60). The dimensions of bias are (60,1), (60,1), (10,1)."
      ],
      "metadata": {
        "id": "iSOQQpaabTAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(layers = [3072, 60, 60, 10]):\n",
        "  W = [[0.0]]\n",
        "  B = [[0.0]]\n",
        "  for i in range(1, len(layers)):\n",
        "    w_temp = np.random.randn(layers[i], layers[i-1])*np.sqrt(2/layers[i-1])\n",
        "    b_temp = np.random.randn(layers[i], 1)*np.sqrt(2/layers[i-1])\n",
        "\n",
        "    W.append(w_temp)\n",
        "    B.append(b_temp)\n",
        "  return W, B"
      ],
      "metadata": {
        "id": "Vls_sFiwZf-n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W, B = initialize_weights()"
      ],
      "metadata": {
        "id": "I9vNAVB0aC_0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = train_data[0]"
      ],
      "metadata": {
        "id": "UpDyqvh8byv7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward Propagation"
      ],
      "metadata": {
        "id": "Nf7VGN5ARo4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output of the first layer"
      ],
      "metadata": {
        "id": "8sUgR6DNbhtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a0 = x\n",
        "z1 = (W[1] @ a0) + B[1]\n",
        "a1 = sigmoid(z1)"
      ],
      "metadata": {
        "id": "_jX7vVvtaH7n"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U239xGaLaJme",
        "outputId": "aef2d655-5cd6-4c96-82e3-0449e4f95474"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output of the second layer"
      ],
      "metadata": {
        "id": "K0TaRaXicAQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z2 = (W[2] @ a1) + B[2]\n",
        "a2 = sigmoid(z2)\n",
        "print(a2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB39bWedaLZi",
        "outputId": "1f446fe7-8e44-4e78-8963-10b38af432b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output of the third layer."
      ],
      "metadata": {
        "id": "bMs9tRJ2cGWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z3 = (W[3] @ a2) + B[3]\n",
        "a3 = sigmoid(z3)\n",
        "print(a3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d0XGX6GaLcJ",
        "outputId": "ff66cf42-219f-4458-8c48-e0906e2c7b02"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of the output of the three layers are (60,1), (60,1), (10,1), respectively, meaning that our function works well."
      ],
      "metadata": {
        "id": "hpEsT6ZDN2--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the output of hidden layers and output layer."
      ],
      "metadata": {
        "id": "xw6ow500cZlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W, B = initialize_weights(layers=[3072, 60, 60, 10])\n",
        "x, y = train_data[0]\n",
        "Z = [[0.0]]\n",
        "A = [x]\n",
        "L = len(B)\n",
        "for i in range(1, L):\n",
        "  z = (W[i] @ A[i-1]) + B[i]\n",
        "  a = sigmoid(z)\n",
        "\n",
        "  Z.append(z)\n",
        "  A.append(a)"
      ],
      "metadata": {
        "id": "J9VkPb8iaLez"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of the output layer."
      ],
      "metadata": {
        "id": "6RQgkdge8GFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A[-1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWOV-1NUaLhB",
        "outputId": "78b118f4-85ff-4ec6-f734-883246253ee7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTwE1JGdPmjY",
        "outputId": "2cef0a92-f844-4b4a-cfc6-dc30304ac6da"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.30849575],\n",
              "       [0.6590959 ],\n",
              "       [0.72038567],\n",
              "       [0.77423845],\n",
              "       [0.79782488],\n",
              "       [0.58541553],\n",
              "       [0.45312934],\n",
              "       [0.72169938],\n",
              "       [0.52324117],\n",
              "       [0.53288498]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## output error\n",
        "Store delta values (**output error**) by creating a dictionary.\n",
        "$$\\delta^{\\ell-1} = \\nabla_{a^{\\ell-1}}\\ C \\otimes \\sigma' (z^{\\ell-1})$$\n"
      ],
      "metadata": {
        "id": "ILx0DKaMcskz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deltas = dict()\n",
        "delta_last = (A[-1] - y)*sigmoid_prime(Z[-1])\n",
        "deltas[L-1] = delta_last"
      ],
      "metadata": {
        "id": "VnMTbJgFaSYS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deltas[L-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHEIo9V8aSa7",
        "outputId": "56cf50ba-3f34-4bec-fdda-50c322d8d129"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0658102 ],\n",
              "       [0.14809127],\n",
              "       [0.1451074 ],\n",
              "       [0.13533167],\n",
              "       [0.12868942],\n",
              "       [0.1420828 ],\n",
              "       [0.11228687],\n",
              "       [0.14495288],\n",
              "       [0.13052766],\n",
              "       [0.13264497]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Neuron Error\n",
        "For $\\ell = L-2,\\cdots,1$, based on output error, the neuron error is: $$\\delta^{\\ell}=\\bigg(\\big(w^{\\ell+1}\\big) ^T\\delta^{\\ell+1}\\bigg) \\otimes\\sigma'(z^{\\ell})$$"
      ],
      "metadata": {
        "id": "J0mW_dTRSdJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for l in range(L-2, 0, -1):\n",
        "  deltas[l] = (W[l+1].T @ deltas[l+1])*sigmoid_prime(Z[l])"
      ],
      "metadata": {
        "id": "1iDW7WUNdCg1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of each layers."
      ],
      "metadata": {
        "id": "q3oAFMvR8S4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deltas[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk05MGR9dDB0",
        "outputId": "66a90b7e-345f-48c1-a398-8a60d4a3b174"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deltas[2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peLHp6R18fy7",
        "outputId": "61d7450f-ad9f-419f-b269-e0d7efdf5673"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deltas[3].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msgY4Ro38f2z",
        "outputId": "1b28910e-609d-4e9e-8819-65a6519f2159"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of the outputs of each layer is right, meaning that our functions for the output error and the neuron error work well."
      ],
      "metadata": {
        "id": "fJpzkBVmTUz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Setup learning rate."
      ],
      "metadata": {
        "id": "nxA333YsdZd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.04"
      ],
      "metadata": {
        "id": "p7NVDmk_aSdr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update weight and bias"
      ],
      "metadata": {
        "id": "-J_Wn0Jtdh1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 4):\n",
        "  W[i] = W[i] - alpha*deltas[i]@A[i-1].T\n",
        "  B[i] = B[i] - alpha*deltas[i]"
      ],
      "metadata": {
        "id": "o3bURo17aYj8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feed forward and make predictions."
      ],
      "metadata": {
        "id": "S5iVVtJ89Dka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(W, B, p, predict_vector = False):\n",
        "  Z =[[0.0]]\n",
        "  A = [p[0]]\n",
        "  L = len(W)\n",
        "  for i in range(1, L):\n",
        "    z = (W[i] @ A[i-1]) + B[i]\n",
        "    a = sigmoid(z)\n",
        "\n",
        "    Z.append(z)\n",
        "    A.append(a)\n",
        "\n",
        "  if predict_vector == True:\n",
        "    return A[-1]\n",
        "  else:\n",
        "    return Z, A\n"
      ],
      "metadata": {
        "id": "-F3rUCvHaYmY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neuron Errors Storage"
      ],
      "metadata": {
        "id": "wVSE6PpQUFAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deltas_dict(W, B, p):\n",
        "  Z, A = forward_pass(W, B, p)\n",
        "  L = len(W)\n",
        "  deltas = dict()\n",
        "  deltas[L-1] = (A[-1] - p[1])*sigmoid_prime(Z[-1])\n",
        "  for l in range(L-2, 0, -1):\n",
        "    deltas[l] = (W[l+1].T @ deltas[l+1]) * sigmoid_prime(Z[l])\n",
        "\n",
        "  return A, deltas\n"
      ],
      "metadata": {
        "id": "Bo0pKuNgUFYG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define loss function."
      ],
      "metadata": {
        "id": "LKnoSvk59LhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE(W, B, data):\n",
        "  c = 0.0\n",
        "  for p in data:\n",
        "    a = forward_pass(W, B, p, predict_vector=True)\n",
        "    c += mse(a, p[1]) # error between a and y\n",
        "  return c/len(data)"
      ],
      "metadata": {
        "id": "JfFGO8vZaYo2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm implementation"
      ],
      "metadata": {
        "id": "pbzRfkyOVEpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate initial loss."
      ],
      "metadata": {
        "id": "RF9zerJB9P_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W, B = initialize_weights()\n",
        "print(f\"Initial Cost = {MSE(W, B, train_data)}\")"
      ],
      "metadata": {
        "id": "xK1CCGH5aYq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7950eb-5183-41fa-a0b1-431243085c12"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 0.9934194082147363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = np.random.randint(0, len(x_test))\n",
        "prediction = np.argmax(forward_pass(W, B, test_data[i], predict_vector=True))\n",
        "print(f\"Predicted Value = {prediction}\")\n",
        "print(f\"Actual Value = {y_test[i]}\")\n",
        "plt.imshow(x_test[i], cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YroKPOhtaYtQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "9fa62606-5608-4d26-9c8f-a2287e7b2d9a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value = 7\n",
            "Actual Value = [9]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predicted value is not consistent with the actual value. "
      ],
      "metadata": {
        "id": "FWSgSiXO9lve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a stochastic gradient descent function with a learning rate $\\alpha = 0.04$ and epochs (the number of iterations) = 3."
      ],
      "metadata": {
        "id": "H4nc8xzj974d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stochastic_gradient_descent(W, B, data, alpha = 0.04, epochs = 3):\n",
        "  L = len(W)\n",
        "  print(f\"Initial Cost = {MSE(W, B, data)}\")\n",
        "  for k in range(epochs):\n",
        "    for p in data:\n",
        "      A, deltas = deltas_dict(W, B, p)\n",
        "      for i in range(1, L):\n",
        "        W[i] = W[i] - alpha*deltas[i]@A[i-1].T\n",
        "        B[i] = B[i] - alpha*deltas[i]\n",
        "    print(f\"{k} Cost = {MSE(W, B, data)}\")"
      ],
      "metadata": {
        "id": "gtx4Iy5JaYvn"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stochastic_gradient_descent(W, B, train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn2cExVi_XkA",
        "outputId": "979c2a27-6ad5-4127-d90a-dba5eb6e6621"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 0.9934194082147363\n",
            "0 Cost = 3.28662926871759e-05\n",
            "1 Cost = 1.5939636222433912e-05\n",
            "2 Cost = 1.0451486149977837e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch's costs progressively decline. The training procedure is effective."
      ],
      "metadata": {
        "id": "ef0RTZKuBB2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We may combine all of the functions to form a class. Meanwhile, we develop another approach for optimizing the algorithm, mini-batch gradient descent."
      ],
      "metadata": {
        "id": "WNrZ0isrAdbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# everything is the same, except for the self\n",
        "class MultilayerPerceptron():\n",
        "  \n",
        "  def __init__(self, layers = [3072, 60, 60, 10]):\n",
        "    self.layers = layers\n",
        "    self.L = len(self.layers)\n",
        "    self.W =[[0.0]]\n",
        "    self.B = [[0.0]]\n",
        "    for i in range(1, self.L):\n",
        "      w_temp = np.random.randn(self.layers[i], self.layers[i - 1])*np.sqrt(2/self.layers[i - 1])\n",
        "      b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
        "\n",
        "      self.W.append(w_temp)\n",
        "      self.B.append(b_temp)\n",
        "\n",
        "  def reset_weights(self, layers = [3072, 60, 60, 10]):\n",
        "    self.layers = layers\n",
        "    self.L = len(self.layers)\n",
        "    self.W = [[0.0]]\n",
        "    self.B = [[0.0]]\n",
        "    for i in range(1, self.L):\n",
        "      w_temp = np.random.randn(self.layers[i], self.layers[i - 1])*np.sqrt(2/self.layers[i - 1])\n",
        "      b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
        "\n",
        "      self.W.append(w_temp)\n",
        "      self.B.append(b_temp)\n",
        "\n",
        "\n",
        "  def forward_pass(self, p, predict_vector = False):\n",
        "    Z =[[0.0]]\n",
        "    A = [p[0]]\n",
        "    for i in range(1, self.L):\n",
        "      z = (self.W[i] @ A[i - 1]) + self.B[i]\n",
        "      a = sigmoid(z)\n",
        "      Z.append(z)\n",
        "      A.append(a)\n",
        "\n",
        "    if predict_vector == True:\n",
        "      return A[-1]\n",
        "    else:\n",
        "      return Z, A\n",
        "\n",
        "  def MSE(self, data):\n",
        "    c = 0.0\n",
        "    for p in data:\n",
        "      a = self.forward_pass(p, predict_vector=True)\n",
        "      c += mse(a, p[1])\n",
        "    return c/len(data)\n",
        "\n",
        "  def deltas_dict(self, p):\n",
        "    Z, A = self.forward_pass(p)\n",
        "    deltas = dict()\n",
        "    deltas[self.L - 1] = (A[-1] - p[1])*sigmoid_prime(Z[-1])\n",
        "    for l in range(self.L - 2, 0, -1):\n",
        "      deltas[l] = (self.W[l+1].T @ deltas[l+1]) * sigmoid_prime(Z[l])\n",
        "\n",
        "    return A, deltas\n",
        "\n",
        "  def stochastic_gradient_descent(self, data, alpha = 0.04, epochs = 3):\n",
        "    print(f\"Initial Cost = {self.MSE(data)}\")\n",
        "    for k in range(epochs):\n",
        "      for p in data:\n",
        "        A, deltas = self.deltas_dict(p)\n",
        "        for i in range(1, self.L):\n",
        "          self.W[i] = self.W[i] - alpha*deltas[i]@A[i - 1].T\n",
        "          self.B[i] = self.B[i] - alpha*deltas[i]\n",
        "    print(f\"{k} Cost = {self.MSE(data)}\")\n",
        "\n",
        "  def mini_batch_gradient_descent(self, data, batch_size = 15, alpha = 0.04, epochs = 3):\n",
        "    print(f\"Initial Cost = {self.MSE(data)}\")\n",
        "    data_length = len(data)\n",
        "    for k in range(epochs):\n",
        "      for j in range(0,data_length-batch_size,batch_size):\n",
        "        delta_list = []\n",
        "        A_list = []\n",
        "        for p in data[j:j + batch_size]:\n",
        "          A, deltas = self.deltas_dict(p)\n",
        "          A_list.append(A)\n",
        "\n",
        "          for i in range(1, self.L):\n",
        "            self.W[i] = self.W[i] - (alpha/batch_size)*sum(da[0][i]@da[1][i - 1].T for da in zip(delta_list, A_list))\n",
        "            self.B[i] = self.B[i] - (alpha/batch_size)*sum(deltas[i] for deltas in delta_list)\n",
        "    print(f\"{k} Cost = {self.MSE(data)}\")"
      ],
      "metadata": {
        "id": "6mASWuveDTrL"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## stochastic gradient descent strategy vs. mini-batch gradient descent strategy "
      ],
      "metadata": {
        "id": "k5uF1Zo0AqKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = MultilayerPerceptron(layers = [3072, 60, 60, 10])"
      ],
      "metadata": {
        "id": "otgXIS-3BK52"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.stochastic_gradient_descent(train_data)"
      ],
      "metadata": {
        "id": "y4a-RTURapBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8fc95d8-1837-4f6f-a4f2-6623aa5c07c8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 1.3039802952116155\n",
            "2 Cost = 1.1002873201495064e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.mini_batch_gradient_descent(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ3jHnWqBKEu",
        "outputId": "0f98641a-9600-4ac4-e8f3-5c57d1e8007f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 1.1002873201495064e-05\n",
            "2 Cost = 1.1002873201495064e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.MSE(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmy2i6NIXfQc",
        "outputId": "aad050f8-7de2-44a2-98cf-612765103841"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0954904804630968e-05"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The mini-batch gradient descent stragety generates smaller cost than the stochastic gradient descent stragety, but it takes longer."
      ],
      "metadata": {
        "id": "LRpvHNoMBrwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Increase nodes in hidden layers\n",
        "setup 120 nodes for both hidden layers, and then make a comparison.\n",
        "\n"
      ],
      "metadata": {
        "id": "DvJsR5mMXubB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = MultilayerPerceptron(layers = [3072, 120, 120, 10])"
      ],
      "metadata": {
        "id": "b19Y0_ZoYMCU"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.stochastic_gradient_descent(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V27QXzp7YBxz",
        "outputId": "e9e2ee40-34cf-4ae8-af71-b28307fde37e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 1.5197036747668118\n",
            "2 Cost = 5.884029933829305e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.mini_batch_gradient_descent(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lBU_1NtYCm7",
        "outputId": "929dc7c9-fd64-43eb-873a-6415c36e76c8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 5.884029933829305e-06\n",
            "2 Cost = 5.884029933829305e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.MSE(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGVVpUbRYHcT",
        "outputId": "6af9615d-ef74-4589-c154-2d9bbebf540a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.834653831432273e-06"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the number of nodes in the hidden layers is increased, the overall cost gets smaller than before. "
      ],
      "metadata": {
        "id": "llIFsg9hfSgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "Patrikar, S. (2019, October 1). Batch, Mini Batch & Stochastic Gradient Descent | By Sushant Patrikar | Towards Data Science. Medium. https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a.\n",
        "\n",
        "S. (2017, December 8). Neural Network Tutorial - Artificial Intelligence | Deep Learning | Edureka. Edureka. https://www.edureka.co/blog/neural-network-tutorial/."
      ],
      "metadata": {
        "id": "aPIu7uIM-JBN"
      }
    }
  ]
}